{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5401ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/floyd/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import oat_python as oat\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab67dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "MIN_RELEVANCE = 0.7\n",
    "MIN_YEAR = 1920\n",
    "MAX_YEAR = 2021  # when the data is from\n",
    "MIN_CONCEPT_FREQ = 0.0001\n",
    "MAX_CONCEPT_FREQ = 0.001\n",
    "YEARS_GRID = np.linspace(0, 1, 100)\n",
    "INV_COUNTS_GRID = np.linspace(0, 1, 40)\n",
    "max_dim = 1\n",
    "years_grid = np.linspace(0, 1, 100)\n",
    "inv_counts_grid = np.linspace(0, 1, 40)\n",
    "\n",
    "def dataprocess(df):\n",
    "    df = df[df['relevance_mean'] >= MIN_RELEVANCE]\n",
    "    df = df[df['year'] >= MIN_YEAR]\n",
    "    num_articles = df['article_id'].nunique()\n",
    "    concept_freq = df.groupby('concept').transform('size') / num_articles\n",
    "    df = df[(concept_freq >= MIN_CONCEPT_FREQ) & (concept_freq <= MAX_CONCEPT_FREQ)]\n",
    "    df = df[['article_id', 'concept', 'year']]\n",
    "\n",
    "    return(df)\n",
    "\n",
    "def conceptprocess(df):\n",
    "    concepts = (\n",
    "            df\n",
    "                .sort_values('year')\n",
    "                .groupby('concept')\n",
    "                .agg(\n",
    "                    year=('year', 'min'),\n",
    "                    count=('article_id', 'nunique')\n",
    "                )\n",
    "                .reset_index()\n",
    "        )\n",
    "\n",
    "    concepts['norm_year'] = (concepts['year'] - MIN_YEAR) / (MAX_YEAR - MIN_YEAR)\n",
    "    concepts['inv_count'] = 1 / concepts['count']\n",
    "    return(concepts)\n",
    "\n",
    "def edgeprocess(df):\n",
    "    edges = df.merge(df, on=['article_id', 'year'], suffixes=['_source', '_target'])\n",
    "    edges = edges[edges['concept_source'] < edges['concept_target']]\n",
    "    edges = edges.groupby(['concept_source', 'concept_target']).agg(\n",
    "            year=('year', 'min'),\n",
    "            count=('article_id', 'nunique')\n",
    "        ).reset_index()\n",
    "\n",
    "    edges['norm_year'] = (edges['year'] - MIN_YEAR) / (MAX_YEAR - MIN_YEAR)\n",
    "    edges['inv_count'] = 1 / edges['count']\n",
    "    return(edges)\n",
    "\n",
    "def graphprocess(concepts,edges):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # add the nodes\n",
    "    G.add_nodes_from([(c, {'norm_year': ny, 'inv_count': ic}) for c, ny, ic in zip(concepts['concept'], concepts['norm_year'], concepts['inv_count'])])\n",
    "\n",
    "    # add the edges\n",
    "    G.add_edges_from([(u, v, {'norm_year': ny, 'inv_count': ic}) for u, v, ny, ic in zip(edges['concept_source'], edges['concept_target'], edges['norm_year'], edges['inv_count'])])\n",
    "    \n",
    "    return(G)\n",
    "\n",
    "def processbetticurve(G):\n",
    "    adj_year = nx.adjacency_matrix(G, weight='norm_year')\n",
    "    adj_year.setdiag([d['norm_year'] for _, d in G.nodes(data=True)])\n",
    "    adj_inv_count = nx.adjacency_matrix(G, weight='inv_count')\n",
    "    adj_inv_count.setdiag([d['inv_count'] for _, d in G.nodes(data=True)])\n",
    "    adj_year = adj_year.sorted_indices()\n",
    "    betti_curves = np.empty((len(years_grid), len(inv_counts_grid), max_dim + 1))\n",
    "\n",
    "    return betti_curves\n",
    "\n",
    "def runcrocker(G, years_grid, inv_counts_grid):\n",
    "    adj_year = nx.adjacency_matrix(G, weight='norm_year')\n",
    "    adj_year.setdiag([d['norm_year'] for _, d in G.nodes(data=True)])\n",
    "    adj_inv_count = nx.adjacency_matrix(G, weight='inv_count')\n",
    "    adj_inv_count.setdiag([d['inv_count'] for _, d in G.nodes(data=True)])\n",
    "    adj_year = adj_year.sorted_indices()\n",
    "\n",
    "    betti_curves = np.empty((len(years_grid), len(inv_counts_grid), max_dim + 1))\n",
    "\n",
    "    for i, c in enumerate(inv_counts_grid):\n",
    "        # zero out things not included\n",
    "        c_adj = adj_year.copy()\n",
    "        c_adj[adj_inv_count > c] = 0\n",
    "        c_adj.eliminate_zeros()\n",
    "\n",
    "        c_adj.setdiag([d['norm_year'] for _, d in G.nodes(data=True)])\n",
    "        c_adj = c_adj.sorted_indices()\n",
    "\n",
    "        if c_adj.nnz == 0 or c_adj.shape[0] == 0:\n",
    "            for d in range(max_dim + 1):\n",
    "                betti_curves[:, i, d] = 0\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            factored = oat.rust.FactoredBoundaryMatrixVr(c_adj, max_dim)\n",
    "            homology = factored.homology(False, False)\n",
    "\n",
    "            for d in range(max_dim + 1):\n",
    "                dim_homology = homology[homology['dimension'] == d]\n",
    "                betti_curves[:, i, d] = ((dim_homology['birth'].values <= years_grid[:, None]) &\n",
    "                                        (dim_homology['death'].values > years_grid[:, None])).sum(axis=1)\n",
    "        except Exception as e:\n",
    "            print(f\"OAT error at inv_count={c:.3f}: {e}\")\n",
    "            for d in range(max_dim + 1):\n",
    "                betti_curves[:, i, d] = 0\n",
    "\n",
    "    return betti_curves\n",
    "\n",
    "def mainfunc(df, years_grid, inv_counts_grid):\n",
    "    df = dataprocess(df)\n",
    "    concepts = conceptprocess(df)\n",
    "    edges = edgeprocess(df)\n",
    "    G = graphprocess(concepts, edges)\n",
    "    betti_curves = runcrocker(G, years_grid, inv_counts_grid)\n",
    "    return betti_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953b6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "        'https://www.dropbox.com/scl/fi/a1t16rtialcw03n50ffkc/concepts_Zoology_608.csv.gz?rlkey=vjv60sfbhofbgvzfzdkrlurl1&st=ciu77f72&dl=1',\n",
    "        compression='gzip',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124a4198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.000e+00, 0.000e+00],\n",
       "        [1.000e+00, 0.000e+00],\n",
       "        [1.000e+00, 0.000e+00],\n",
       "        ...,\n",
       "        [1.000e+00, 0.000e+00],\n",
       "        [1.000e+00, 0.000e+00],\n",
       "        [1.000e+00, 0.000e+00]],\n",
       "\n",
       "       [[2.000e+00, 0.000e+00],\n",
       "        [2.000e+00, 0.000e+00],\n",
       "        [2.000e+00, 0.000e+00],\n",
       "        ...,\n",
       "        [2.000e+00, 0.000e+00],\n",
       "        [2.000e+00, 0.000e+00],\n",
       "        [2.000e+00, 0.000e+00]],\n",
       "\n",
       "       [[4.000e+00, 0.000e+00],\n",
       "        [4.000e+00, 0.000e+00],\n",
       "        [4.000e+00, 0.000e+00],\n",
       "        ...,\n",
       "        [4.000e+00, 0.000e+00],\n",
       "        [4.000e+00, 0.000e+00],\n",
       "        [4.000e+00, 0.000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[4.139e+03, 0.000e+00],\n",
       "        [4.139e+03, 0.000e+00],\n",
       "        [4.138e+03, 0.000e+00],\n",
       "        ...,\n",
       "        [2.565e+03, 8.600e+01],\n",
       "        [2.565e+03, 8.600e+01],\n",
       "        [3.130e+02, 3.536e+03]],\n",
       "\n",
       "       [[4.143e+03, 0.000e+00],\n",
       "        [4.143e+03, 0.000e+00],\n",
       "        [4.142e+03, 0.000e+00],\n",
       "        ...,\n",
       "        [2.538e+03, 9.300e+01],\n",
       "        [2.538e+03, 9.300e+01],\n",
       "        [2.660e+02, 3.849e+03]],\n",
       "\n",
       "       [[4.146e+03, 0.000e+00],\n",
       "        [4.146e+03, 0.000e+00],\n",
       "        [4.145e+03, 0.000e+00],\n",
       "        ...,\n",
       "        [2.503e+03, 9.900e+01],\n",
       "        [2.503e+03, 9.900e+01],\n",
       "        [2.180e+02, 4.327e+03]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betti = mainfunc(df,YEARS_GRID,INV_COUNTS_GRID)\n",
    "betti"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
